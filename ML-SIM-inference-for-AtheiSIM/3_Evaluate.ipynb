{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-SIM Inference script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import skimage\n",
    "from skimage.measure import compare_ssim\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import scipy.ndimage as ndimage\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from skimage import io,exposure,img_as_ubyte\n",
    "import glob\n",
    "import argparse\n",
    "from models import GetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadModel(opt):\n",
    "    print('Loading model')\n",
    "    print(opt)\n",
    "\n",
    "    net = GetModel(opt)\n",
    "    print('loading checkpoint',opt.weights)\n",
    "    checkpoint = torch.load(opt.weights,map_location=opt.device)\n",
    "\n",
    "    if type(checkpoint) is dict:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def SIM_reconstruct_singleStack(model, opt, stack):\n",
    "    \n",
    "    def prepimg(stack,self):\n",
    "\n",
    "        inputimg = stack[:9]\n",
    "\n",
    "        if self.nch_in == 6:\n",
    "            inputimg = inputimg[[0,1,3,4,6,7]]\n",
    "        elif self.nch_in == 3:\n",
    "            inputimg = inputimg[[0,4,8]]\n",
    "\n",
    "        if inputimg.shape[1] > 512 or inputimg.shape[2] > 512:\n",
    "            print('Over 512x512! Cropping')\n",
    "            inputimg = inputimg[:,:512,:512]\n",
    "\n",
    "        inputimg = inputimg.astype('float') / np.max(inputimg) # used to be /255\n",
    "        widefield = np.mean(inputimg,0) \n",
    "\n",
    "        if self.norm == 'adapthist':\n",
    "            for i in range(len(inputimg)):\n",
    "                inputimg[i] = exposure.equalize_adapthist(inputimg[i],clip_limit=0.001)\n",
    "            widefield = exposure.equalize_adapthist(widefield,clip_limit=0.001)\n",
    "            inputimg = torch.from_numpy(inputimg).float()\n",
    "            widefield = torch.from_numpy(widefield).float()\n",
    "        else:\n",
    "            # normalise \n",
    "            inputimg = torch.from_numpy(inputimg).float()\n",
    "            widefield = torch.from_numpy(widefield).float()\n",
    "            widefield = (widefield - torch.min(widefield)) / (torch.max(widefield) - torch.min(widefield))\n",
    "\n",
    "            if self.norm == 'minmax':\n",
    "                for i in range(len(inputimg)):\n",
    "                    inputimg[i] = (inputimg[i] - torch.min(inputimg[i])) / (torch.max(inputimg[i]) - torch.min(inputimg[i]))\n",
    "\n",
    "        return inputimg,widefield    \n",
    "    \n",
    "    inputimg, wf = prepimg(stack,opt)\n",
    "    wf = (255*wf.numpy()).astype('uint8')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sr = model(inputimg.unsqueeze(0).to(opt.device))\n",
    "        sr = sr.cpu()\n",
    "        sr = torch.clamp(sr,min=0,max=1) \n",
    "\n",
    "    sr = sr.squeeze().numpy()\n",
    "    sr = (255*sr).astype('uint8')\n",
    "    if opt.norm == 'adapthist':\n",
    "        sr = exposure.equalize_adapthist(sr,clip_limit=0.01)    \n",
    "    return inputimg, wf, sr\n",
    "        \n",
    "def SIM_reconstruct(model, opt):\n",
    "\n",
    "    os.makedirs('%s' % opt.out,exist_ok=True)\n",
    "    files = glob.glob('%s/*.tif' % opt.root)\n",
    "    count = 0\n",
    "    \n",
    "    for iidx,imgfile in enumerate(files):\n",
    "        \n",
    "        print('[%d/%d] Reconstructing %s' % (iidx+1,len(files),imgfile))\n",
    "        stack = io.imread(imgfile)\n",
    "        \n",
    "        if stack.shape[0] >= 2*opt.nch_in:\n",
    "            for stack_idx in range(stack.shape[0] // opt.nch_in):\n",
    "                stackSubset = stack[stack_idx*opt.nch_in:(stack_idx+1)*opt.nch_in]\n",
    "                inputimg, wf, sr = SIM_reconstruct_singleStack(model, opt, stackSubset)\n",
    "                skimage.io.imsave('%s/test_wf_%d.jpg' % (opt.out,count), wf)\n",
    "                skimage.io.imsave('%s/test_sr_%d.jpg' % (opt.out,count), sr) \n",
    "                count += 1\n",
    "        else:\n",
    "            inputimg, wf, sr = SIM_reconstruct_singleStack(model, opt, stack)              \n",
    "            skimage.io.imsave('%s/test_wf_%d.jpg' % (opt.out,count), wf)\n",
    "            skimage.io.imsave('%s/test_sr_%d.jpg' % (opt.out,count), sr) \n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'AtheiSIM_batch_data'\n",
    "opt.out = 'test-output_model-1'\n",
    "opt.task = 'simin_gtout'\n",
    "opt.norm = 'minmax'\n",
    "opt.dataset = 'fouriersim'\n",
    "\n",
    "opt.model = 'rcan'\n",
    "\n",
    "# data\n",
    "opt.imageSize = 512\n",
    "opt.weights = 'DIV2K_randomised_3x3_20200317.pth'\n",
    "\n",
    "# input/output layer options\n",
    "opt.scale = 1\n",
    "opt.nch_in = 9\n",
    "opt.nch_out = 1\n",
    "\n",
    "# architecture options \n",
    "opt.narch = 0\n",
    "opt.n_resblocks = 10\n",
    "opt.n_resgroups = 3\n",
    "opt.reduction = 16\n",
    "opt.n_feats = 96\n",
    "\n",
    "# test options\n",
    "opt.test = False\n",
    "opt.cpu = True\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "Namespace(cpu=True, dataset='fouriersim', device=device(type='cpu'), imageSize=512, model='rcan', n_feats=96, n_resblocks=10, n_resgroups=3, narch=0, nch_in=9, nch_out=1, norm='minmax', out='test-output_model-1', reduction=16, root='AtheiSIM_batch_data', scale=1, task='simin_gtout', test=False, weights='DIV2K_randomised_3x3_20200317.pth')\n",
      "loading checkpoint DIV2K_randomised_3x3_20200317.pth\n",
      "[1/1] Reconstructing AtheiSIM_batch_data\\AtheiSIM-concat.tif\n"
     ]
    }
   ],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'AtheiSIM_batch_data'\n",
    "opt.out = 'test-output_model-2'\n",
    "opt.task = 'simin_gtout'\n",
    "opt.dataset = 'fouriersim'\n",
    "opt.norm = 'minmax' ## trained on 'adapthist', but 'minmax' may be better for tests \n",
    "opt.model = 'rcan'\n",
    "\n",
    "# data\n",
    "opt.imageSize = 512\n",
    "opt.weights = \"0216_SIMRec_0214_rndAll_rcan_continued.pth\"\n",
    "\n",
    "# input/output layer options\n",
    "opt.scale = 1\n",
    "opt.nch_in = 9\n",
    "opt.nch_out = 1\n",
    "\n",
    "# architecture options \n",
    "opt.narch = 0\n",
    "opt.n_resgroups = 3\n",
    "opt.n_resblocks = 10\n",
    "opt.n_feats = 48\n",
    "opt.reduction = 16\n",
    "opt.narch = 0\n",
    "\n",
    "    \n",
    "# test options\n",
    "opt.test = False\n",
    "opt.cpu = True\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "Namespace(cpu=True, dataset='fouriersim', device=device(type='cpu'), imageSize=512, model='rcan', n_feats=48, n_resblocks=10, n_resgroups=3, narch=0, nch_in=9, nch_out=1, norm='minmax', out='test-output_model-2', reduction=16, root='AtheiSIM_batch_data', scale=1, task='simin_gtout', test=False, weights='0216_SIMRec_0214_rndAll_rcan_continued.pth')\n",
      "loading checkpoint 0216_SIMRec_0214_rndAll_rcan_continued.pth\n",
      "[1/1] Reconstructing AtheiSIM_batch_data\\AtheiSIM-concat.tif\n"
     ]
    }
   ],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 -- adapthist norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'AtheiSIM_batch_data'\n",
    "opt.out = 'test-output_model-2-adapthist'\n",
    "opt.task = 'simin_gtout'\n",
    "opt.dataset = 'fouriersim'\n",
    "opt.norm = 'adapthist' ## trained on 'adapthist', but 'minmax' may be better for tests \n",
    "opt.model = 'rcan'\n",
    "\n",
    "# data\n",
    "opt.imageSize = 512\n",
    "opt.weights = \"0216_SIMRec_0214_rndAll_rcan_continued.pth\"\n",
    "\n",
    "# input/output layer options\n",
    "opt.scale = 1\n",
    "opt.nch_in = 9\n",
    "opt.nch_out = 1\n",
    "\n",
    "# architecture options \n",
    "opt.narch = 0\n",
    "opt.n_resgroups = 3\n",
    "opt.n_resblocks = 10\n",
    "opt.n_feats = 48\n",
    "opt.reduction = 16\n",
    "opt.narch = 0\n",
    "\n",
    "    \n",
    "# test options\n",
    "opt.test = False\n",
    "opt.cpu = True\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "Namespace(cpu=True, dataset='fouriersim', device=device(type='cpu'), imageSize=512, model='rcan', n_feats=48, n_resblocks=10, n_resgroups=3, narch=0, nch_in=9, nch_out=1, norm='adapthist', out='test-output_model-2-adapthist', reduction=16, root='AtheiSIM_batch_data', scale=1, task='simin_gtout', test=False, weights='0216_SIMRec_0214_rndAll_rcan_continued.pth')\n",
      "loading checkpoint 0216_SIMRec_0214_rndAll_rcan_continued.pth\n",
      "[1/1] Reconstructing AtheiSIM_batch_data\\AtheiSIM-concat.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
