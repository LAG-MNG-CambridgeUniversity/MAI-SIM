{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-SIM Inference script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torchvision\r\n",
    "import skimage\r\n",
    "from skimage.measure import compare_ssim\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "from PIL import Image\r\n",
    "import scipy.ndimage as ndimage\r\n",
    "import torch.nn as nn\r\n",
    "import os\r\n",
    "from skimage import io,exposure,img_as_ubyte\r\n",
    "import glob\r\n",
    "import argparse\r\n",
    "from models import GetModel\r\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
<<<<<<< Updated upstream
<<<<<<< Updated upstream
    "def LoadModel(opt):\n",
    "    print('Loading model')\n",
    "    print(opt)\n",
    "\n",
    "    net = GetModel(opt)\n",
    "    print('loading checkpoint',opt.weights)\n",
    "    checkpoint = torch.load(opt.weights,map_location=opt.device)\n",
    "\n",
    "    if type(checkpoint) is dict:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    net.module.load_state_dict(state_dict)\n",
    "    #net.load_state_dict(state_dict)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def SIM_reconstruct_singleStack(model, opt, stack):\n",
    "    \n",
    "    def prepimg(stack,self):\n",
    "\n",
    "        inputimg = stack[:9]\n",
    "\n",
    "        if self.nch_in == 6:\n",
    "            inputimg = inputimg[[0,1,3,4,6,7]]\n",
    "        elif self.nch_in == 3:\n",
    "            inputimg = inputimg[[0,4,8]]\n",
    "\n",
    "        if inputimg.shape[1] > 512 or inputimg.shape[2] > 512:\n",
    "            # print('Over 512x512! Cropping')\n",
    "            inputimg = inputimg[:,:512,:512]\n",
    "\n",
    "        inputimg = inputimg.astype('float') / np.max(inputimg) # used to be /255\n",
    "        widefield = np.mean(inputimg,0) \n",
    "\n",
    "        if self.norm == 'adapthist':\n",
    "            for i in range(len(inputimg)):\n",
    "                inputimg[i] = exposure.equalize_adapthist(inputimg[i],clip_limit=0.001)\n",
    "            widefield = exposure.equalize_adapthist(widefield,clip_limit=0.001)\n",
    "            inputimg = torch.from_numpy(inputimg).float()\n",
    "            widefield = torch.from_numpy(widefield).float()\n",
    "        else:\n",
    "            # normalise \n",
    "            inputimg = torch.from_numpy(inputimg).float()\n",
    "            widefield = torch.from_numpy(widefield).float()\n",
    "            widefield = (widefield - torch.min(widefield)) / (torch.max(widefield) - torch.min(widefield))\n",
    "\n",
    "            if self.norm == 'minmax':\n",
    "                for i in range(len(inputimg)):\n",
    "                    inputimg[i] = (inputimg[i] - torch.min(inputimg[i])) / (torch.max(inputimg[i]) - torch.min(inputimg[i]))\n",
    "\n",
    "        return inputimg,widefield    \n",
    "    \n",
    "    inputimg, wf = prepimg(stack,opt)\n",
    "    wf = (65535*wf.numpy()).astype('uint16')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sr = model(inputimg.unsqueeze(0).to(opt.device))\n",
    "        sr = sr.cpu()\n",
    "        sr = torch.clamp(sr,min=0,max=1) \n",
    "\n",
    "    sr = sr.squeeze().numpy()\n",
    "    \n",
    "    if opt.norm == 'adapthist':\n",
    "        sr = exposure.equalize_adapthist(sr,clip_limit=0.01) \n",
    "    \n",
    "    sr = (65535*sr).astype('uint16')    \n",
    "\n",
    "    return inputimg, wf, sr\n",
    "        \n",
    "def SIM_reconstruct(model, opt):\n",
    "\n",
    "    os.makedirs('%s' % opt.out,exist_ok=True)\n",
    "    files = glob.glob('%s/*.tif' % opt.root)\n",
    "    count = 0\n",
    "    \n",
    "    for iidx,imgfile in enumerate(files):\n",
    "        \n",
    "        print('Reconstructing image stack: %s [%d/%d]' % (os.path.basename(imgfile),iidx+1,len(files)))\n",
    "        stack = io.imread(imgfile)\n",
    "        \n",
    "        if stack.shape[0] >= 2*opt.nch_in:\n",
    "            nImgs = stack.shape[0] // opt.nch_in\n",
    "            sr = np.zeros([512,512,nImgs]) \n",
    "            wf = np.zeros([512,512,nImgs]) \n",
    "\n",
    "            for stack_idx in tqdm(range(stack.shape[0] // opt.nch_in)):\n",
    "                stackSubset = stack[stack_idx*opt.nch_in:(stack_idx+1)*opt.nch_in]\n",
    "                _, wf[:,:,stack_idx], sr[:,:,stack_idx] = SIM_reconstruct_singleStack(model, opt, stackSubset)\n",
    "\n",
    "            wf = np.moveaxis(wf,2,0)\n",
    "            sr = np.moveaxis(sr,2,0)\n",
    "\n",
    "            filename = os.path.basename(imgfile)[:-4]\n",
    "            svPath = opt.out + '/' + filename +'_wf.tif'\n",
    "            skimage.io.imsave(svPath, wf.astype('uint16'))\n",
    "            svPath = opt.out + '/' + filename +'_sr.tif'\n",
    "            skimage.io.imsave(svPath, sr.astype('uint16')) \n",
    "            count += 1\n",
    "        else:\n",
    "            inputimg, wf, sr = SIM_reconstruct_singleStack(model, opt, stack)              \n",
    "            filename = os.path.basename(imgfile)[:-4]\n",
    "            svPath = opt.out + '/' + filename +'_wf.tif'\n",
    "            skimage.io.imsave(svPath, wf.astype('uint16'))\n",
    "            svPath = opt.out + '/' + filename +'_sr.tif'\n",
    "            skimage.io.imsave(svPath, sr.astype('uint16'))\n",
=======
=======
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
    "def LoadModel(opt):\r\n",
    "    print('Loading model')\r\n",
    "    print(opt)\r\n",
    "\r\n",
    "    net = GetModel(opt)\r\n",
    "    print('loading checkpoint',opt.weights)\r\n",
    "    checkpoint = torch.load(opt.weights,map_location=opt.device)\r\n",
    "\r\n",
    "    if type(checkpoint) is dict:\r\n",
    "        state_dict = checkpoint['state_dict']\r\n",
    "    else:\r\n",
    "        state_dict = checkpoint\r\n",
    "\r\n",
    "    net.module.load_state_dict(state_dict)\r\n",
    "    #net.load_state_dict(state_dict)\r\n",
    "\r\n",
    "    return net\r\n",
    "\r\n",
    "\r\n",
    "def SIM_reconstruct_singleStack(model, opt, stack):\r\n",
    "    \r\n",
    "    def prepimg(stack,self):\r\n",
    "\r\n",
    "        inputimg = stack[:9]\r\n",
    "\r\n",
    "        if self.nch_in == 6:\r\n",
    "            inputimg = inputimg[[0,1,3,4,6,7]]\r\n",
    "        elif self.nch_in == 3:\r\n",
    "            inputimg = inputimg[[0,4,8]]\r\n",
    "\r\n",
    "        if inputimg.shape[1] > 512 or inputimg.shape[2] > 512:\r\n",
    "            # print('Over 512x512! Cropping')\r\n",
    "            inputimg = inputimg[:,:512,:512]\r\n",
    "\r\n",
    "        inputimg = inputimg.astype('float') / np.max(inputimg) # used to be /255\r\n",
    "        widefield = np.mean(inputimg,0) \r\n",
    "\r\n",
    "        if self.norm == 'adapthist':\r\n",
    "            for i in range(len(inputimg)):\r\n",
    "                inputimg[i] = exposure.equalize_adapthist(inputimg[i],clip_limit=0.001)\r\n",
    "            widefield = exposure.equalize_adapthist(widefield,clip_limit=0.001)\r\n",
    "            inputimg = torch.from_numpy(inputimg).float()\r\n",
    "            widefield = torch.from_numpy(widefield).float()\r\n",
    "        else:\r\n",
    "            # normalise \r\n",
    "            inputimg = torch.from_numpy(inputimg).float()\r\n",
    "            widefield = torch.from_numpy(widefield).float()\r\n",
    "            widefield = (widefield - torch.min(widefield)) / (torch.max(widefield) - torch.min(widefield))\r\n",
    "\r\n",
    "            if self.norm == 'minmax':\r\n",
    "                for i in range(len(inputimg)):\r\n",
    "                    inputimg[i] = (inputimg[i] - torch.min(inputimg[i])) / (torch.max(inputimg[i]) - torch.min(inputimg[i]))\r\n",
    "\r\n",
    "        return inputimg,widefield    \r\n",
    "    \r\n",
    "    inputimg, wf = prepimg(stack,opt)\r\n",
    "    wf = (32000*wf.numpy()).astype('uint16')\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        sr = model(inputimg.unsqueeze(0).to(opt.device))\r\n",
    "        sr = sr.cpu()\r\n",
    "        sr = torch.clamp(sr,min=0,max=1) \r\n",
    "\r\n",
    "    sr = sr.squeeze().numpy()\r\n",
    "    \r\n",
    "    if opt.norm == 'adapthist':\r\n",
    "        sr = exposure.equalize_adapthist(sr,clip_limit=0.01) \r\n",
    "    \r\n",
    "    sr = (32000*sr).astype('uint16')    \r\n",
    "\r\n",
    "    return inputimg, wf, sr\r\n",
    "        \r\n",
    "def SIM_reconstruct(model, opt):\r\n",
    "\r\n",
    "    os.makedirs('%s' % opt.out,exist_ok=True)\r\n",
    "    files = glob.glob('%s/*.tif' % opt.root)\r\n",
    "    count = 0\r\n",
    "    \r\n",
    "    for iidx,imgfile in enumerate(files):\r\n",
    "        \r\n",
    "        print('Reconstructing image stack: %s [%d/%d]' % (os.path.basename(imgfile),iidx+1,len(files)))\r\n",
    "        stack = io.imread(imgfile)\r\n",
    "        \r\n",
    "        if stack.shape[0] >= 2*opt.nch_in:\r\n",
    "            nImgs = stack.shape[0] // opt.nch_in\r\n",
    "            sr = np.zeros([512,512,nImgs]) \r\n",
    "            wf = np.zeros([512,512,nImgs]) \r\n",
    "\r\n",
    "            for stack_idx in tqdm(range(stack.shape[0] // opt.nch_in)):\r\n",
    "                stackSubset = stack[stack_idx*opt.nch_in:(stack_idx+1)*opt.nch_in]\r\n",
    "                _, wf[:,:,stack_idx], sr[:,:,stack_idx] = SIM_reconstruct_singleStack(model, opt, stackSubset)\r\n",
    "\r\n",
    "            wf = np.moveaxis(wf,2,0)\r\n",
    "            sr = np.moveaxis(sr,2,0)\r\n",
    "\r\n",
    "            filename = os.path.basename(imgfile)[:-4]\r\n",
    "            svPath = opt.out + '/' + filename +'_wf.tif'\r\n",
    "            skimage.io.imsave(svPath, wf.astype('uint16'))\r\n",
    "            svPath = opt.out + '/' + filename +'_sr.tif'\r\n",
    "            skimage.io.imsave(svPath, sr.astype('uint16')) \r\n",
    "            count += 1\r\n",
    "        else:\r\n",
    "            inputimg, wf, sr = SIM_reconstruct_singleStack(model, opt, stack)              \r\n",
    "            skimage.io.imsave('%s/test_wf_%d.jpg' % (opt.out,count), wf)\r\n",
    "            skimage.io.imsave('%s/test_sr_%d.jpg' % (opt.out,count), sr) \r\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = argparse.Namespace()\r\n",
    "\r\n",
    "\r\n",
    "opt.root = 'D:/SIM_Data/07-05-2021/488 cholesterol 561 mito 647 lysosomes/1_18/to process/'\r\n",
    "opt.out = 'D:/SIM_Data/07-05-2021/488 cholesterol 561 mito 647 lysosomes/1_18/to process/ML-Reconstructions'\r\n",
    "opt.task = 'simin_gtout'\r\n",
    "opt.norm = 'minmax'\r\n",
    "opt.dataset = 'fouriersim'\r\n",
    "\r\n",
    "opt.model = 'rcan'\r\n",
    "\r\n",
    "# data\r\n",
    "opt.imageSize = 512\r\n",
    "opt.weights = 'DIV2K_randomised_3x3_20200317.pth'\r\n",
    "\r\n",
    "# input/output layer options\r\n",
    "opt.scale = 1\r\n",
    "opt.nch_in = 9\r\n",
    "opt.nch_out = 1\r\n",
    "\r\n",
    "# architecture options \r\n",
    "opt.narch = 0\r\n",
    "opt.n_resblocks = 10\r\n",
    "opt.n_resgroups = 3\r\n",
    "opt.reduction = 16\r\n",
    "opt.n_feats = 96\r\n",
    "\r\n",
    "# test options\r\n",
    "opt.test = False\r\n",
    "opt.cpu = False\r\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
<<<<<<< Updated upstream
<<<<<<< Updated upstream
    "opt = argparse.Namespace()\n",
    "\n",
    "opt.root = 'D:/User/Edward/Downloads/SIM_reconstruction/to process'\n",
    "opt.out = 'D:/User/Edward/Downloads/SIM_reconstruction/results'\n",
    "opt.task = 'simin_gtout'\n",
    "opt.dataset = 'fouriersim'\n",
    "opt.norm = 'minmax' ## trained on 'adapthist', but 'minmax' may be better for tests \n",
    "opt.model = 'rcan'\n",
    "\n",
    "# data\n",
    "opt.imageSize = 512\n",
    "opt.weights = \"0216_SIMRec_0214_rndAll_rcan_continued.pth\"\n",
    "\n",
    "# input/output layer options\n",
    "opt.scale = 1\n",
    "opt.nch_in = 9\n",
    "opt.nch_out = 1\n",
    "\n",
    "# architecture options \n",
    "opt.narch = 0\n",
    "opt.n_resgroups = 3\n",
    "opt.n_resblocks = 10\n",
    "opt.n_feats = 48\n",
    "opt.reduction = 16\n",
    "opt.narch = 0\n",
    "\n",
    "    \n",
    "# test options\n",
    "opt.test = False\n",
    "opt.cpu = False\n",
=======
=======
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
    "opt = argparse.Namespace()\r\n",
    "\r\n",
    "opt.root = 'D:/SIM_Data/16-06-2021/488mito 561ER 647tubulin/rolling_13/to process'\r\n",
    "opt.out = 'D:/SIM_Data/16-06-2021/488mito 561ER 647tubulin/rolling_13/results'\r\n",
    "opt.task = 'simin_gtout'\r\n",
    "opt.dataset = 'fouriersim'\r\n",
    "opt.norm = 'minmax' ## trained on 'adapthist', but 'minmax' may be better for tests \r\n",
    "opt.model = 'rcan'\r\n",
    "\r\n",
    "# data\r\n",
    "opt.imageSize = 512\r\n",
    "opt.weights = \"0216_SIMRec_0214_rndAll_rcan_continued.pth\"\r\n",
    "\r\n",
    "# input/output layer options\r\n",
    "opt.scale = 1\r\n",
    "opt.nch_in = 9\r\n",
    "opt.nch_out = 1\r\n",
    "\r\n",
    "# architecture options \r\n",
    "opt.narch = 0\r\n",
    "opt.n_resgroups = 3\r\n",
    "opt.n_resblocks = 10\r\n",
    "opt.n_feats = 48\r\n",
    "opt.reduction = 16\r\n",
    "opt.narch = 0\r\n",
    "\r\n",
    "    \r\n",
    "# test options\r\n",
    "opt.test = False\r\n",
    "opt.cpu = False\r\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 -- adapthist norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = argparse.Namespace()\r\n",
    "\r\n",
    "opt.root = 'D:/SIM_Data/07-05-2021/488 cholesterol 561 mito 647 lysosomes/1_18/to process/for ML-SIM'\r\n",
    "opt.out = 'D:/SIM_Data/07-05-2021/488 cholesterol 561 mito 647 lysosomes/1_18/to process/for ML-SIM/ML-Reconstructions'\r\n",
    "opt.task = 'simin_gtout'\r\n",
    "opt.dataset = 'fouriersim'\r\n",
    "opt.norm = 'adapthist' ## trained on 'adapthist', but 'minmax' may be better for tests \r\n",
    "opt.model = 'rcan'\r\n",
    "\r\n",
    "# data\r\n",
    "opt.imageSize = 512\r\n",
    "opt.weights = \"0216_SIMRec_0214_rndAll_rcan_continued.pth\"\r\n",
    "\r\n",
    "# input/output layer options\r\n",
    "opt.scale = 1\r\n",
    "opt.nch_in = 9\r\n",
    "opt.nch_out = 1\r\n",
    "\r\n",
    "# architecture options \r\n",
    "opt.narch = 0\r\n",
    "opt.n_resgroups = 3\r\n",
    "opt.n_resblocks = 10\r\n",
    "opt.n_feats = 48\r\n",
    "opt.reduction = 16\r\n",
    "opt.narch = 0\r\n",
    "\r\n",
    "    \r\n",
    "# test options\r\n",
    "opt.test = False\r\n",
    "opt.cpu = False\r\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() and not opt.cpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LoadModel(opt)\n",
    "SIM_reconstruct(net,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('py37': conda)",
   "name": "python379jvsc74a57bd06c99de76283e2fc5beb3cee89d2cb0712cee351c2202cbec91ab7d93b4fff068"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}